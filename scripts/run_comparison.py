"""Basic vs Agent RAG ë¹„êµ í‰ê°€ ëŸ¬ë„ˆ

ë‘ ëª¨ë“œë¡œ ë™ì¼í•œ ì§ˆë¬¸ì…‹ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

Usage:
    # ì „ì²´ ì‹¤í–‰
    uv run python scripts/run_comparison.py

    # íŠ¹ì • ì§ˆë¬¸ë§Œ
    uv run python scripts/run_comparison.py --questions 1,2,3

    # ë ˆë²¨ í•„í„°
    uv run python scripts/run_comparison.py --level 1

    # í•œ ëª¨ë“œë§Œ ì‹¤í–‰ (ì´ë¯¸ ê²°ê³¼ê°€ ìˆì„ ë•Œ)
    uv run python scripts/run_comparison.py --mode basic
    uv run python scripts/run_comparison.py --mode agent

    # ê¸°ì¡´ ê²°ê³¼ë¡œ ë¹„êµë§Œ
    uv run python scripts/run_comparison.py --compare-only data/results/basic.json data/results/agent.json
"""

import argparse
import json
import re
import sys
from collections import defaultdict
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src import create_service
from src.cost import calculate_cost, format_cost
from tqdm import tqdm


# =============================================================================
# Key Facts ìë™ ë§¤ì¹­
# =============================================================================


def check_key_facts(answer: str, key_facts: list[str]) -> dict:
    """ë‹µë³€ì—ì„œ key_facts í¬í•¨ ì—¬ë¶€ ì²´í¬

    Args:
        answer: ìƒì„±ëœ ë‹µë³€
        key_facts: ì •ë‹µì— í¬í•¨ë˜ì–´ì•¼ í•  í•µì‹¬ ì‚¬ì‹¤ ë¦¬ìŠ¤íŠ¸

    Returns:
        dict: matched(ë§¤ì¹­ëœ facts), missed(ëˆ„ë½ëœ facts), accuracy(ì •í™•ë„)
    """
    if not key_facts:
        return {"matched": [], "missed": [], "accuracy": 1.0}
    if not answer:
        return {"matched": [], "missed": key_facts, "accuracy": 0.0}

    answer_lower = answer.lower()
    matched = []
    missed = []

    for fact in key_facts:
        fact_lower = fact.lower()
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ìˆ«ì, í•œê¸€ ë‹¨ì–´)
        keywords = re.findall(r"[\d]+|[ê°€-í£]+", fact_lower)
        # ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë§Œ í•„í„° (2ì ì´ìƒ)
        meaningful_keywords = [kw for kw in keywords if len(kw) > 1]

        if not meaningful_keywords:
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ ì²´í¬
            if fact_lower in answer_lower:
                matched.append(fact)
            else:
                missed.append(fact)
        else:
            # ëª¨ë“  í‚¤ì›Œë“œê°€ ë‹µë³€ì— í¬í•¨ë˜ë©´ ë§¤ì¹­
            if all(kw in answer_lower for kw in meaningful_keywords):
                matched.append(fact)
            else:
                missed.append(fact)

    accuracy = len(matched) / len(key_facts)
    return {"matched": matched, "missed": missed, "accuracy": round(accuracy, 4)}


# =============================================================================
# ê²½ë¡œ ì„¤ì •
# =============================================================================

QUESTIONS_PATH = PROJECT_ROOT / "data" / "questions" / "question_set.json"
RESULTS_DIR = PROJECT_ROOT / "data" / "results"


# =============================================================================
# ì§ˆë¬¸ì…‹ ë¡œë“œ
# =============================================================================


def load_questions(path: Path = QUESTIONS_PATH) -> list[dict]:
    """ì§ˆë¬¸ì…‹ ë¡œë“œ"""
    with open(path, encoding="utf-8") as f:
        data = json.load(f)
    return data["questions"]


def filter_questions(
    questions: list[dict],
    question_ids: list[int] | None = None,
    level: int | None = None,
) -> list[dict]:
    """ì§ˆë¬¸ í•„í„°ë§"""
    result = questions

    if question_ids:
        result = [q for q in result if q["id"] in question_ids]

    if level:
        result = [q for q in result if q["level"] == level]

    return result


# =============================================================================
# ì‹¤í–‰
# =============================================================================


def run_mode(
    mode: str,
    questions: list[dict],
    project_id: int = 334,
) -> list[dict]:
    """íŠ¹ì • ëª¨ë“œë¡œ ì§ˆë¬¸ì…‹ ì‹¤í–‰"""
    print(f"\nğŸš€ {mode.upper()} ëª¨ë“œ ì‹¤í–‰ ì¤‘...")

    service = create_service(mode=mode, project_id=project_id)
    results = []

    for q in tqdm(questions, desc=f"{mode} ì²˜ë¦¬"):
        try:
            result = service.query(q["question"])
            results.append(
                {
                    "id": q["id"],
                    "level": q["level"],
                    "category": q["category"],
                    "question": q["question"],
                    "expected_answer": q.get("expected_answer", ""),
                    "key_facts": q.get("key_facts", []),
                    "documents_required": q.get("documents_required", []),
                    "answer": result.answer,
                    "input_tokens": result.input_tokens,
                    "output_tokens": result.output_tokens,
                    "latency_ms": round(result.latency_ms, 1),
                    "model": result.model,
                    # ëª¨ë“œ ê³µí†µ ì •ë³´
                    "sources": result.sources,
                    "timings": result.timings,
                    # Agent ëª¨ë“œ ì „ìš©
                    "tool_calls": result.tool_calls if mode == "agent" else [],
                    "call_history": result.call_history if mode == "agent" else [],
                }
            )
        except Exception as e:
            print(f"\nâŒ ì§ˆë¬¸ {q['id']} ì‹¤íŒ¨: {e}")
            results.append(
                {
                    "id": q["id"],
                    "level": q["level"],
                    "category": q["category"],
                    "question": q["question"],
                    "expected_answer": q.get("expected_answer", ""),
                    "key_facts": q.get("key_facts", []),
                    "documents_required": q.get("documents_required", []),
                    "answer": f"ERROR: {e}",
                    "input_tokens": 0,
                    "output_tokens": 0,
                    "latency_ms": 0,
                    "model": "",
                    "error": str(e),
                    "sources": [],
                    "tool_calls": [],
                    "call_history": [],
                    "timings": {},
                }
            )

    return results


# =============================================================================
# í†µê³„ ê³„ì‚°
# =============================================================================


def calculate_summary(results: list[dict]) -> dict:
    """ê²°ê³¼ í†µê³„ ê³„ì‚°"""
    if not results:
        return {}

    total = len(results)
    latencies = [r["latency_ms"] for r in results if r["latency_ms"] > 0]
    input_tokens = sum(r["input_tokens"] for r in results)
    output_tokens = sum(r["output_tokens"] for r in results)

    # ë ˆë²¨ë³„ í†µê³„
    by_level = defaultdict(lambda: {"count": 0, "latencies": []})
    for r in results:
        level = r["level"]
        by_level[level]["count"] += 1
        if r["latency_ms"] > 0:
            by_level[level]["latencies"].append(r["latency_ms"])

    level_stats = {}
    for level, data in sorted(by_level.items()):
        avg_latency = sum(data["latencies"]) / len(data["latencies"]) if data["latencies"] else 0
        level_stats[str(level)] = {
            "count": data["count"],
            "avg_latency_ms": round(avg_latency, 1),
        }

    return {
        "total_questions": total,
        "success_count": len(latencies),
        "error_count": total - len(latencies),
        "avg_latency_ms": round(sum(latencies) / len(latencies), 1) if latencies else 0,
        "min_latency_ms": round(min(latencies), 1) if latencies else 0,
        "max_latency_ms": round(max(latencies), 1) if latencies else 0,
        "total_input_tokens": input_tokens,
        "total_output_tokens": output_tokens,
        "total_tokens": input_tokens + output_tokens,
        "by_level": level_stats,
    }


# =============================================================================
# ë¹„êµ ë° ë³‘í•©
# =============================================================================


def merge_results(basic_results: list[dict], agent_results: list[dict]) -> list[dict]:
    """Basicê³¼ Agent ê²°ê³¼ ë³‘í•©"""
    # IDë¡œ ì¸ë±ì‹±
    agent_by_id = {r["id"]: r for r in agent_results}

    merged = []
    for b in basic_results:
        q_id = b["id"]
        a = agent_by_id.get(q_id, {})
        key_facts = b.get("key_facts", [])

        # Key Facts ìë™ ë§¤ì¹­
        basic_check = check_key_facts(b["answer"], key_facts)
        agent_check = check_key_facts(a.get("answer", ""), key_facts)

        merged.append(
            {
                "id": q_id,
                "level": b["level"],
                "category": b["category"],
                "question": b["question"],
                "expected_answer": b.get("expected_answer", ""),
                "key_facts": key_facts,
                # Basic ê²°ê³¼
                "answer_basic": b["answer"],
                "latency_basic_ms": b["latency_ms"],
                "tokens_basic": {
                    "input": b["input_tokens"],
                    "output": b["output_tokens"],
                    "total": b["input_tokens"] + b["output_tokens"],
                },
                "sources_basic": b.get("sources", []),
                "timings_basic": b.get("timings", {}),
                # Basic Key Facts ë§¤ì¹­
                "key_facts_matched_basic": basic_check["matched"],
                "key_facts_missed_basic": basic_check["missed"],
                "accuracy_basic": basic_check["accuracy"],
                # Agent ê²°ê³¼
                "answer_agent": a.get("answer", "N/A"),
                "latency_agent_ms": a.get("latency_ms", 0),
                "tokens_agent": {
                    "input": a.get("input_tokens", 0),
                    "output": a.get("output_tokens", 0),
                    "total": a.get("input_tokens", 0) + a.get("output_tokens", 0),
                },
                "sources_agent": a.get("sources", []),
                "timings_agent": a.get("timings", {}),
                "tool_calls": a.get("tool_calls", []),
                "call_history": a.get("call_history", []),
                # Agent Key Facts ë§¤ì¹­
                "key_facts_matched_agent": agent_check["matched"],
                "key_facts_missed_agent": agent_check["missed"],
                "accuracy_agent": agent_check["accuracy"],
                # í‰ê°€ (ìˆ˜ë™ ì…ë ¥ìš©)
                "winner": "",
                "notes": "",
            }
        )

    return merged


def calculate_comparison_stats(merged: list[dict]) -> dict:
    """ë¹„êµ í†µê³„ ê³„ì‚°"""
    basic_latencies = [m["latency_basic_ms"] for m in merged if m["latency_basic_ms"] > 0]
    agent_latencies = [m["latency_agent_ms"] for m in merged if m["latency_agent_ms"] > 0]

    # í† í° ê³„ì‚° (ì´ì œ ê°ì²´ í˜•íƒœ)
    basic_input = sum(m["tokens_basic"]["input"] for m in merged)
    basic_output = sum(m["tokens_basic"]["output"] for m in merged)
    basic_tokens = basic_input + basic_output

    agent_input = sum(m["tokens_agent"]["input"] for m in merged)
    agent_output = sum(m["tokens_agent"]["output"] for m in merged)
    agent_tokens = agent_input + agent_output

    # ë¹„ìš© ê³„ì‚° (ì •í™•í•œ input/output ê°’ ì‚¬ìš©)
    basic_cost = calculate_cost(basic_input, basic_output)
    agent_cost = calculate_cost(agent_input, agent_output)

    # ì •í™•ë„ í†µê³„
    basic_accuracies = [m["accuracy_basic"] for m in merged if m.get("key_facts")]
    agent_accuracies = [m["accuracy_agent"] for m in merged if m.get("key_facts")]

    # íš¨ìœ¨ì„± ì§€í‘œ ê³„ì‚°
    basic_matched_facts = sum(len(m.get("key_facts_matched_basic", [])) for m in merged)
    agent_matched_facts = sum(len(m.get("key_facts_matched_agent", [])) for m in merged)
    total_latency_basic = sum(basic_latencies)
    total_latency_agent = sum(agent_latencies)

    efficiency = {}
    if basic_matched_facts > 0:
        efficiency["basic"] = {
            "tokens_per_fact": round(basic_tokens / basic_matched_facts, 1),
            "latency_per_fact_ms": round(total_latency_basic / basic_matched_facts, 1),
            "cost_per_fact_krw": round(basic_cost["total_krw"] / basic_matched_facts, 2),
        }
    if agent_matched_facts > 0:
        efficiency["agent"] = {
            "tokens_per_fact": round(agent_tokens / agent_matched_facts, 1),
            "latency_per_fact_ms": round(total_latency_agent / agent_matched_facts, 1),
            "cost_per_fact_krw": round(agent_cost["total_krw"] / agent_matched_facts, 2),
        }

    # ë ˆë²¨ë³„ ë¹„êµ
    by_level = defaultdict(
        lambda: {
            "count": 0,
            "basic_latencies": [],
            "agent_latencies": [],
        }
    )
    for m in merged:
        level = m["level"]
        by_level[level]["count"] += 1
        if m["latency_basic_ms"] > 0:
            by_level[level]["basic_latencies"].append(m["latency_basic_ms"])
        if m["latency_agent_ms"] > 0:
            by_level[level]["agent_latencies"].append(m["latency_agent_ms"])

    level_stats = {}
    for level, data in sorted(by_level.items()):
        basic_avg = sum(data["basic_latencies"]) / len(data["basic_latencies"]) if data["basic_latencies"] else 0
        agent_avg = sum(data["agent_latencies"]) / len(data["agent_latencies"]) if data["agent_latencies"] else 0
        level_stats[str(level)] = {
            "count": data["count"],
            "basic_avg_latency_ms": round(basic_avg, 1),
            "agent_avg_latency_ms": round(agent_avg, 1),
            "latency_diff_ms": round(agent_avg - basic_avg, 1),
        }

    return {
        "total_questions": len(merged),
        "basic": {
            "avg_latency_ms": round(sum(basic_latencies) / len(basic_latencies), 1) if basic_latencies else 0,
            "tokens": {
                "input": basic_input,
                "output": basic_output,
                "total": basic_tokens,
            },
            "cost_usd": round(basic_cost["total_usd"], 4),
            "cost_krw": round(basic_cost["total_krw"], 0),
        },
        "agent": {
            "avg_latency_ms": round(sum(agent_latencies) / len(agent_latencies), 1) if agent_latencies else 0,
            "tokens": {
                "input": agent_input,
                "output": agent_output,
                "total": agent_tokens,
            },
            "cost_usd": round(agent_cost["total_usd"], 4),
            "cost_krw": round(agent_cost["total_krw"], 0),
        },
        "latency_diff_ms": round(
            (sum(agent_latencies) / len(agent_latencies) if agent_latencies else 0)
            - (sum(basic_latencies) / len(basic_latencies) if basic_latencies else 0),
            1,
        ),
        "token_diff": {
            "input": agent_input - basic_input,
            "output": agent_output - basic_output,
            "total": agent_tokens - basic_tokens,
        },
        "cost_diff_usd": round(agent_cost["total_usd"] - basic_cost["total_usd"], 4),
        "cost_diff_krw": round(agent_cost["total_krw"] - basic_cost["total_krw"], 0),
        "accuracy": {
            "basic_avg": round(sum(basic_accuracies) / len(basic_accuracies), 4) if basic_accuracies else 0,
            "agent_avg": round(sum(agent_accuracies) / len(agent_accuracies), 4) if agent_accuracies else 0,
            "basic_perfect": sum(1 for a in basic_accuracies if a == 1.0),
            "agent_perfect": sum(1 for a in agent_accuracies if a == 1.0),
        },
        "efficiency": efficiency,
        "matched_facts": {
            "basic": basic_matched_facts,
            "agent": agent_matched_facts,
        },
        "by_level": level_stats,
    }


# =============================================================================
# ì €ì¥
# =============================================================================


def save_results(
    results: list[dict],
    mode: str,
    run_id: str,
    output_dir: Path = RESULTS_DIR,
) -> Path:
    """ë‹¨ì¼ ëª¨ë“œ ê²°ê³¼ ì €ì¥"""
    output_dir.mkdir(parents=True, exist_ok=True)

    summary = calculate_summary(results)

    output = {
        "run_id": run_id,
        "mode": mode,
        "results": results,
        "summary": summary,
    }

    filename = f"{run_id}_{mode}.json"
    output_path = output_dir / filename

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    return output_path


def save_comparison(
    merged: list[dict],
    run_id: str,
    output_dir: Path = RESULTS_DIR,
) -> Path:
    """ë¹„êµ ê²°ê³¼ ì €ì¥"""
    output_dir.mkdir(parents=True, exist_ok=True)

    stats = calculate_comparison_stats(merged)

    output = {
        "run_id": run_id,
        "type": "comparison",
        "results": merged,
        "stats": stats,
    }

    filename = f"{run_id}_comparison.json"
    output_path = output_dir / filename

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    return output_path


def save_agent_call_log(
    merged: list[dict],
    run_id: str,
    output_dir: Path = RESULTS_DIR,
) -> Path:
    """Agent ë„êµ¬ í˜¸ì¶œ ë¡œê·¸ íŒŒì¼ ìƒì„±

    ê° ì§ˆë¬¸ë³„ë¡œ Agentê°€ ì–´ë–¤ ìˆœì„œë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí–ˆëŠ”ì§€,
    ì–´ë–¤ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í–ˆê³  ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¾ì•˜ëŠ”ì§€ ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    lines = []
    lines.append("=" * 80)
    lines.append(f"Agent RAG ë„êµ¬ í˜¸ì¶œ ë¡œê·¸ - {run_id}")
    lines.append("=" * 80)
    lines.append("")

    for m in merged:
        q_id = m["id"]
        question = m["question"]
        call_history = m.get("call_history", [])

        lines.append("-" * 80)
        lines.append(f"Q{q_id}: {question}")
        lines.append("-" * 80)

        if not call_history:
            lines.append("  (ë„êµ¬ í˜¸ì¶œ ì—†ìŒ)")
        else:
            for call in call_history:
                call_idx = call.get("call_index", "?")
                tool = call.get("tool", "unknown")
                query = call.get("query", "")
                elapsed = call.get("elapsed_ms", 0)
                result_count = call.get("result_count", 0)

                lines.append(f"  [{call_idx}] {tool}")
                lines.append(f"      Query: \"{query}\"")
                lines.append(f"      Results: {result_count}ê°œ ({elapsed:.1f}ms)")

                # ë¬¸ì„œ ëª©ë¡
                docs = call.get("documents", [])
                if docs:
                    for doc in docs:
                        rank = doc.get("rank", "?")
                        fname = doc.get("file_name", "unknown")
                        score = doc.get("score", 0)
                        preview = doc.get("text_preview", "")[:60]
                        lines.append(f"        #{rank} [{score:.3f}] {fname}")
                        lines.append(f"            \"{preview}...\"")

                lines.append("")

        # Agent ë‹µë³€ ìš”ì•½
        answer = m.get("answer_agent", "")
        answer_preview = answer[:200] + "..." if len(answer) > 200 else answer
        lines.append(f"  â†’ ë‹µë³€: {answer_preview}")
        lines.append(f"  â†’ ì •í™•ë„: {m.get('accuracy_agent', 0)*100:.0f}%")
        lines.append("")

    # íŒŒì¼ ì €ì¥
    filename = f"{run_id}_agent_calls.log"
    output_path = output_dir / filename

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    return output_path


# =============================================================================
# ì¶œë ¥
# =============================================================================


def print_comparison_summary(merged: list[dict]) -> None:
    """ë¹„êµ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    stats = calculate_comparison_stats(merged)

    print("\n" + "=" * 70)
    print("ğŸ“Š Basic vs Agent ë¹„êµ ê²°ê³¼")
    print("=" * 70)

    print(f"\nì´ ì§ˆë¬¸ ìˆ˜: {stats['total_questions']}")

    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚                         ì „ì²´ ë¹„êµ                                â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚  {'í•­ëª©':<20} {'Basic':>15} {'Agent':>15} {'ì°¨ì´':>12} â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(
        f"â”‚  {'í‰ê·  ë ˆì´í„´ì‹œ (ms)':<20} {stats['basic']['avg_latency_ms']:>15,.1f} {stats['agent']['avg_latency_ms']:>15,.1f} {stats['latency_diff_ms']:>+12,.1f} â”‚"
    )
    print(
        f"â”‚  {'ì…ë ¥ í† í°':<20} {stats['basic']['tokens']['input']:>15,} {stats['agent']['tokens']['input']:>15,} {stats['token_diff']['input']:>+12,} â”‚"
    )
    print(
        f"â”‚  {'ì¶œë ¥ í† í°':<20} {stats['basic']['tokens']['output']:>15,} {stats['agent']['tokens']['output']:>15,} {stats['token_diff']['output']:>+12,} â”‚"
    )
    print(
        f"â”‚  {'ì´ í† í°':<20} {stats['basic']['tokens']['total']:>15,} {stats['agent']['tokens']['total']:>15,} {stats['token_diff']['total']:>+12,} â”‚"
    )
    print(
        f"â”‚  {'ë¹„ìš© (USD)':<20} {'$' + format(stats['basic']['cost_usd'], '.4f'):>15} {'$' + format(stats['agent']['cost_usd'], '.4f'):>15} {'$' + format(stats['cost_diff_usd'], '+.4f'):>12} â”‚"
    )
    print(
        f"â”‚  {'ë¹„ìš© (KRW)':<20} {'â‚©' + format(int(stats['basic']['cost_krw']), ','):>15} {'â‚©' + format(int(stats['agent']['cost_krw']), ','):>15} {'â‚©' + format(int(stats['cost_diff_krw']), '+,'):>12} â”‚"
    )
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # ì •í™•ë„ í†µê³„
    if stats.get("accuracy"):
        acc = stats["accuracy"]
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚                         ì •í™•ë„ (Key Facts)                       â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚  Basic: í‰ê·  {acc['basic_avg']*100:.1f}%, ì™„ë²½ ë§¤ì¹­ {acc['basic_perfect']}ê°œ                            â”‚")
        print(f"â”‚  Agent: í‰ê·  {acc['agent_avg']*100:.1f}%, ì™„ë²½ ë§¤ì¹­ {acc['agent_perfect']}ê°œ                            â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # íš¨ìœ¨ì„± ì§€í‘œ
    if stats.get("efficiency"):
        eff = stats["efficiency"]
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚                         íš¨ìœ¨ì„± ì§€í‘œ                              â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        if "basic" in eff:
            print(f"â”‚  Basic: {eff['basic']['tokens_per_fact']:.0f} tokens/fact, "
                  f"{eff['basic']['latency_per_fact_ms']:.0f}ms/fact, "
                  f"â‚©{eff['basic']['cost_per_fact_krw']:.2f}/fact     â”‚")
        if "agent" in eff:
            print(f"â”‚  Agent: {eff['agent']['tokens_per_fact']:.0f} tokens/fact, "
                  f"{eff['agent']['latency_per_fact_ms']:.0f}ms/fact, "
                  f"â‚©{eff['agent']['cost_per_fact_krw']:.2f}/fact     â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    print("\në ˆë²¨ë³„ ë ˆì´í„´ì‹œ ë¹„êµ:")
    for level, data in stats["by_level"].items():
        basic_avg = data["basic_avg_latency_ms"]
        agent_avg = data["agent_avg_latency_ms"]
        diff = data["latency_diff_ms"]
        ratio = agent_avg / basic_avg if basic_avg > 0 else 0
        print(f"  Level {level}: Basic {basic_avg:,.0f}ms â†’ Agent {agent_avg:,.0f}ms ({diff:+,.0f}ms, {ratio:.1f}x)")

    print("=" * 70)


# =============================================================================
# HTML ë¦¬í¬íŠ¸ ìƒì„±
# =============================================================================


def generate_comparison_report(
    merged: list[dict],
    run_id: str,
    output_dir: Path = RESULTS_DIR,
) -> Path:
    """ë¹„êµ ê²°ê³¼ HTML ë¦¬í¬íŠ¸ ìƒì„±"""
    stats = calculate_comparison_stats(merged)

    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG ë¹„êµ í‰ê°€ - {run_id}</title>
    <style>
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        body {{ font-family: 'Segoe UI', Tahoma, sans-serif; background: #f5f5f5; padding: 20px; line-height: 1.6; }}
        .container {{ max-width: 1400px; margin: 0 auto; }}

        h1 {{ color: #333; margin-bottom: 10px; }}
        .run-id {{ color: #666; font-size: 14px; margin-bottom: 30px; }}

        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 30px; }}
        .stat-card {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .stat-card.basic {{ border-left: 4px solid #4CAF50; }}
        .stat-card.agent {{ border-left: 4px solid #2196F3; }}
        .stat-card.diff {{ border-left: 4px solid #FF9800; }}
        .stat-label {{ font-size: 12px; color: #666; text-transform: uppercase; }}
        .stat-value {{ font-size: 28px; font-weight: bold; color: #333; }}
        .stat-unit {{ font-size: 14px; color: #999; }}

        .level-chart {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 30px; }}
        .level-chart h2 {{ margin-bottom: 20px; font-size: 18px; }}
        .level-row {{ display: flex; align-items: center; margin-bottom: 15px; }}
        .level-label {{ width: 80px; font-weight: bold; }}
        .level-bars {{ flex: 1; display: flex; flex-direction: column; gap: 4px; }}
        .bar-container {{ display: flex; align-items: center; }}
        .bar {{ height: 24px; border-radius: 4px; display: flex; align-items: center; padding-left: 8px; color: white; font-size: 12px; min-width: 60px; }}
        .bar.basic {{ background: #4CAF50; }}
        .bar.agent {{ background: #2196F3; }}
        .bar-label {{ margin-left: 10px; font-size: 12px; color: #666; }}

        .questions {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .questions h2 {{ margin-bottom: 20px; font-size: 18px; }}

        .question-card {{ border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 15px; overflow: hidden; }}
        .question-header {{ background: #fafafa; padding: 15px; cursor: pointer; display: flex; justify-content: space-between; align-items: center; }}
        .question-header:hover {{ background: #f0f0f0; }}
        .question-meta {{ display: flex; gap: 10px; align-items: center; }}
        .question-id {{ font-weight: bold; color: #333; }}
        .question-level {{ font-size: 12px; padding: 2px 8px; border-radius: 4px; background: #e0e0e0; }}
        .question-level.l1 {{ background: #E8F5E9; color: #2E7D32; }}
        .question-level.l2 {{ background: #E3F2FD; color: #1565C0; }}
        .question-level.l3 {{ background: #FFF3E0; color: #E65100; }}
        .question-level.l4 {{ background: #FCE4EC; color: #C2185B; }}
        .question-text {{ flex: 1; margin-left: 15px; color: #333; }}
        .question-stats {{ display: flex; gap: 15px; font-size: 12px; color: #666; }}

        .question-body {{ padding: 15px; display: none; border-top: 1px solid #e0e0e0; }}
        .question-card.open .question-body {{ display: block; }}

        .answer-compare {{ display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 15px; }}
        .answer-box {{ padding: 15px; border-radius: 8px; }}
        .answer-box.basic {{ background: #E8F5E9; }}
        .answer-box.agent {{ background: #E3F2FD; }}
        .answer-box.expected {{ background: #FFF8E1; grid-column: 1 / -1; }}
        .answer-label {{ font-size: 12px; font-weight: bold; color: #666; margin-bottom: 8px; text-transform: uppercase; }}
        .answer-content {{ font-size: 14px; white-space: pre-wrap; }}

        .key-facts {{ margin-top: 10px; }}
        .key-facts-label {{ font-size: 12px; color: #666; margin-bottom: 5px; }}
        .key-fact {{ display: inline-block; font-size: 12px; padding: 2px 8px; margin: 2px; background: #e0e0e0; border-radius: 4px; }}

        .toggle-icon {{ transition: transform 0.2s; }}
        .question-card.open .toggle-icon {{ transform: rotate(180deg); }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š Basic vs Agent RAG ë¹„êµ í‰ê°€</h1>
        <div class="run-id">Run ID: {run_id}</div>

        <div class="stats-grid">
            <div class="stat-card basic">
                <div class="stat-label">Basic í‰ê·  ë ˆì´í„´ì‹œ</div>
                <div class="stat-value">{stats["basic"]["avg_latency_ms"]:,.0f}<span class="stat-unit">ms</span></div>
            </div>
            <div class="stat-card agent">
                <div class="stat-label">Agent í‰ê·  ë ˆì´í„´ì‹œ</div>
                <div class="stat-value">{stats["agent"]["avg_latency_ms"]:,.0f}<span class="stat-unit">ms</span></div>
            </div>
            <div class="stat-card diff">
                <div class="stat-label">ë ˆì´í„´ì‹œ ì°¨ì´</div>
                <div class="stat-value">{stats["latency_diff_ms"]:+,.0f}<span class="stat-unit">ms</span></div>
            </div>
            <div class="stat-card basic">
                <div class="stat-label">Basic ì´ í† í°</div>
                <div class="stat-value">{stats["basic"]["tokens"]["total"]:,}</div>
            </div>
            <div class="stat-card agent">
                <div class="stat-label">Agent ì´ í† í°</div>
                <div class="stat-value">{stats["agent"]["tokens"]["total"]:,}</div>
            </div>
            <div class="stat-card diff">
                <div class="stat-label">í† í° ì°¨ì´</div>
                <div class="stat-value">{stats["token_diff"]["total"]:+,}</div>
            </div>
            <div class="stat-card basic">
                <div class="stat-label">Basic ë¹„ìš©</div>
                <div class="stat-value">${stats["basic"]["cost_usd"]:.4f}<span class="stat-unit"> (â‚©{int(stats["basic"]["cost_krw"]):,})</span></div>
            </div>
            <div class="stat-card agent">
                <div class="stat-label">Agent ë¹„ìš©</div>
                <div class="stat-value">${stats["agent"]["cost_usd"]:.4f}<span class="stat-unit"> (â‚©{int(stats["agent"]["cost_krw"]):,})</span></div>
            </div>
            <div class="stat-card diff">
                <div class="stat-label">ë¹„ìš© ì°¨ì´</div>
                <div class="stat-value">${stats["cost_diff_usd"]:+.4f}<span class="stat-unit"> (â‚©{int(stats["cost_diff_krw"]):+,})</span></div>
            </div>
        </div>

        <div class="level-chart">
            <h2>ë ˆë²¨ë³„ ë ˆì´í„´ì‹œ ë¹„êµ</h2>
            {generate_level_bars(stats)}
        </div>

        <div class="questions">
            <h2>ì§ˆë¬¸ë³„ ìƒì„¸ ë¹„êµ ({len(merged)}ê°œ)</h2>
            {generate_question_cards(merged)}
        </div>
    </div>

    <script>
        document.querySelectorAll('.question-header').forEach(header => {{
            header.addEventListener('click', () => {{
                header.parentElement.classList.toggle('open');
            }});
        }});
    </script>
</body>
</html>"""

    output_path = output_dir / f"{run_id}_comparison.html"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(html)

    return output_path


def generate_level_bars(stats: dict) -> str:
    """ë ˆë²¨ë³„ ë§‰ëŒ€ ì°¨íŠ¸ HTML ìƒì„±"""
    max_latency = max(
        max(d["basic_avg_latency_ms"] for d in stats["by_level"].values()),
        max(d["agent_avg_latency_ms"] for d in stats["by_level"].values()),
    )

    html = ""
    for level, data in stats["by_level"].items():
        basic_width = (data["basic_avg_latency_ms"] / max_latency * 100) if max_latency > 0 else 0
        agent_width = (data["agent_avg_latency_ms"] / max_latency * 100) if max_latency > 0 else 0

        html += f"""
        <div class="level-row">
            <div class="level-label">Level {level}</div>
            <div class="level-bars">
                <div class="bar-container">
                    <div class="bar basic" style="width: {basic_width}%">{data["basic_avg_latency_ms"]:,.0f}ms</div>
                    <span class="bar-label">Basic</span>
                </div>
                <div class="bar-container">
                    <div class="bar agent" style="width: {agent_width}%">{data["agent_avg_latency_ms"]:,.0f}ms</div>
                    <span class="bar-label">Agent</span>
                </div>
            </div>
        </div>
        """

    return html


def generate_question_cards(merged: list[dict]) -> str:
    """ì§ˆë¬¸ ì¹´ë“œ HTML ìƒì„±"""
    html = ""
    for m in merged:
        level_class = f"l{m['level']}"
        key_facts_html = ""
        if m.get("key_facts"):
            facts = "".join(f'<span class="key-fact">{f}</span>' for f in m["key_facts"])
            key_facts_html = f'<div class="key-facts"><div class="key-facts-label">í•µì‹¬ ì •ë³´:</div>{facts}</div>'

        html += f"""
        <div class="question-card">
            <div class="question-header">
                <div class="question-meta">
                    <span class="question-id">Q{m["id"]}</span>
                    <span class="question-level {level_class}">Level {m["level"]}</span>
                </div>
                <div class="question-text">{m["question"]}</div>
                <div class="question-stats">
                    <span>Basic: {m["latency_basic_ms"]:,.0f}ms</span>
                    <span>Agent: {m["latency_agent_ms"]:,.0f}ms</span>
                </div>
                <span class="toggle-icon">â–¼</span>
            </div>
            <div class="question-body">
                <div class="answer-box expected">
                    <div class="answer-label">ğŸ“Œ ì˜ˆìƒ ì •ë‹µ</div>
                    <div class="answer-content">{m["expected_answer"]}</div>
                    {key_facts_html}
                </div>
                <div class="answer-compare">
                    <div class="answer-box basic">
                        <div class="answer-label">ğŸŸ¢ Basic RAG ({m["latency_basic_ms"]:,.0f}ms, {m["tokens_basic"]["total"]:,} tokens, ì •í™•ë„: {m["accuracy_basic"]*100:.0f}%)</div>
                        <div class="answer-content">{m["answer_basic"]}</div>
                    </div>
                    <div class="answer-box agent">
                        <div class="answer-label">ğŸ”µ Agent RAG ({m["latency_agent_ms"]:,.0f}ms, {m["tokens_agent"]["total"]:,} tokens, ì •í™•ë„: {m["accuracy_agent"]*100:.0f}%)</div>
                        <div class="answer-content">{m["answer_agent"]}</div>
                    </div>
                </div>
            </div>
        </div>
        """

    return html


# =============================================================================
# ë©”ì¸
# =============================================================================


def main():
    parser = argparse.ArgumentParser(description="Basic vs Agent RAG ë¹„êµ í‰ê°€")
    parser.add_argument(
        "--mode",
        choices=["basic", "agent", "both"],
        default="both",
        help="ì‹¤í–‰í•  ëª¨ë“œ (ê¸°ë³¸: both)",
    )
    parser.add_argument(
        "--questions",
        type=str,
        help="ì‹¤í–‰í•  ì§ˆë¬¸ ID (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: 1,2,3)",
    )
    parser.add_argument(
        "--level",
        type=int,
        choices=[1, 2, 3, 4],
        help="ì‹¤í–‰í•  ë ˆë²¨ í•„í„°",
    )
    parser.add_argument(
        "--project-id",
        type=int,
        default=334,
        help="í”„ë¡œì íŠ¸ ID (ê¸°ë³¸: 334)",
    )
    parser.add_argument(
        "--compare-only",
        nargs=2,
        metavar=("BASIC_JSON", "AGENT_JSON"),
        help="ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ë¡œ ë¹„êµë§Œ ì‹¤í–‰",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì„¤ì •ë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ",
    )

    args = parser.parse_args()
    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ê¸°ì¡´ ê²°ê³¼ë¡œ ë¹„êµë§Œ
    if args.compare_only:
        basic_path, agent_path = args.compare_only
        with open(basic_path, encoding="utf-8") as f:
            basic_data = json.load(f)
        with open(agent_path, encoding="utf-8") as f:
            agent_data = json.load(f)

        merged = merge_results(basic_data["results"], agent_data["results"])

        # ì €ì¥ ë° ì¶œë ¥
        comparison_path = save_comparison(merged, run_id)
        html_path = generate_comparison_report(merged, run_id)
        log_path = save_agent_call_log(merged, run_id)

        print_comparison_summary(merged)
        print(f"\nğŸ’¾ ë¹„êµ ê²°ê³¼: {comparison_path}")
        print(f"ğŸ“Š HTML ë¦¬í¬íŠ¸: {html_path}")
        print(f"ğŸ“ Agent í˜¸ì¶œ ë¡œê·¸: {log_path}")
        return

    # ì§ˆë¬¸ ë¡œë“œ ë° í•„í„°
    questions = load_questions()
    question_ids = [int(x) for x in args.questions.split(",")] if args.questions else None
    questions = filter_questions(questions, question_ids, args.level)

    if not questions:
        print("âŒ ì‹¤í–‰í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # dry-run
    if args.dry_run:
        print(f"\nğŸ”§ ì‹¤í–‰ ì„¤ì •")
        print(f"  ëª¨ë“œ: {args.mode}")
        print(f"  ì§ˆë¬¸ ìˆ˜: {len(questions)}")
        print(f"  í”„ë¡œì íŠ¸ ID: {args.project_id}")
        print("\nì‹¤í–‰ ëŒ€ìƒ ì§ˆë¬¸:")
        for q in questions:
            print(f"  [{q['id']}] Level {q['level']}: {q['question'][:40]}...")
        return

    print(f"\nğŸ“ {len(questions)}ê°œ ì§ˆë¬¸ ì‹¤í–‰ ì˜ˆì •")

    basic_results = []
    agent_results = []

    # ì‹¤í–‰
    if args.mode in ["basic", "both"]:
        basic_results = run_mode("basic", questions, args.project_id)
        basic_path = save_results(basic_results, "basic", run_id)
        print(f"\nğŸ’¾ Basic ê²°ê³¼: {basic_path}")

    if args.mode in ["agent", "both"]:
        agent_results = run_mode("agent", questions, args.project_id)
        agent_path = save_results(agent_results, "agent", run_id)
        print(f"\nğŸ’¾ Agent ê²°ê³¼: {agent_path}")

    # ë¹„êµ
    if args.mode == "both" and basic_results and agent_results:
        merged = merge_results(basic_results, agent_results)
        comparison_path = save_comparison(merged, run_id)
        html_path = generate_comparison_report(merged, run_id)
        log_path = save_agent_call_log(merged, run_id)

        print_comparison_summary(merged)
        print(f"\nğŸ’¾ ë¹„êµ ê²°ê³¼: {comparison_path}")
        print(f"ğŸ“Š HTML ë¦¬í¬íŠ¸: {html_path}")
        print(f"ğŸ“ Agent í˜¸ì¶œ ë¡œê·¸: {log_path}")


if __name__ == "__main__":
    main()
