# í–¥í›„ ë„ì… ê²€í†  ê¸°ìˆ 

> í˜„ì¬ëŠ” ê³¼í•˜ì§€ë§Œ, í”„ë¡œì íŠ¸ê°€ ì„±ìˆ™í•˜ë©´ ë„ì…ì„ ê³ ë ¤í•  ë§Œí•œ ê¸°ìˆ ë“¤
>
> **ìµœì¢… ì—…ë°ì´íŠ¸: 2025-12-31** (2025ë…„ ìµœì‹  ì—°êµ¬ ë°˜ì˜)

---

## ìš°ì„ ìˆœìœ„ ìš”ì•½

| ê¸°ìˆ  | ë³µì¡ë„ | íš¨ê³¼ | ìš°ì„ ìˆœìœ„ | ë¹„ê³  |
|------|--------|------|----------|------|
| **LongContextReorder** | ë‚®ìŒ | ì¤‘ê°„ | âœ… í˜„ì¬ ê³„íš | Lost in the Middle ëŒ€ì‘ |
| **HybridSearch (RRF)** | ë‚®ìŒ | ë†’ìŒ | âœ… í˜„ì¬ ê³„íš | BM25 + KNN |
| **FlashRank Reranker** | ë‚®ìŒ | ì¤‘-ìƒ | âœ… í˜„ì¬ ê³„íš | CPU ìµœì í™” |
| **BGE-reranker-v2-m3** | ë‚®ìŒ | ìƒ | ğŸ”„ FlashRank ëŒ€ì²´ ê²€í†  | ë” ì •í™•, ë¬´ë£Œ |
| **HyDE** | ì¤‘ê°„ | ì¤‘-ìƒ | â³ ê²€ìƒ‰ í’ˆì§ˆ ì´ìŠˆ ì‹œ | ê°€ìƒ ë¬¸ì„œ ì„ë² ë”© |
| **Query Decomposition** | ì¤‘ê°„ | ë†’ìŒ | â³ ë³µì¡ ì§ˆë¬¸ ëŒ€ì‘ ì‹œ | ë‹¤ë‹¨ê³„ ì§ˆë¬¸ ë¶„í•´ |
| **Late Chunking** | ì¤‘ê°„ | ì¤‘-ìƒ | â³ ì¸ë±ì‹± ê°œì„  ì‹œ | ë¬¸ë§¥ ë³´ì¡´ ì²­í‚¹ |
| **Contextual Retrieval** | ë†’ìŒ | ë†’ìŒ | â³ ë¹„ìš© í—ˆìš© ì‹œ | Anthropic ë°©ì‹ |
| **Voyage AI Embedding** | ë‚®ìŒ | ë†’ìŒ | ğŸ”„ Titan ëŒ€ì²´ ê²€í†  | SOTA ì„ë² ë”© |
| **Semantic Chunking** | ì¤‘ê°„ | ì¤‘-ìƒ | â³ ì²­í‚¹ ê°œì„  ì‹œ | ì˜ë¯¸ ë‹¨ìœ„ ë¶„í•  |
| **Context Compression** | ë†’ìŒ | ë†’ìŒ | â³ í† í° ë¹„ìš© ë¬¸ì œì‹œ | LLM 2íšŒ í˜¸ì¶œ |
| **ColBERT v2** | ë†’ìŒ | ë†’ìŒ | â³ ëŒ€ê·œëª¨ ê²€ìƒ‰ ì‹œ | Late Interaction |

---

## 1. HyDE (Hypothetical Document Embeddings) â­ ì‹ ê·œ

### ê°œìš”
ì§ˆë¬¸ì„ ê°€ìƒì˜ ë‹µë³€ ë¬¸ì„œë¡œ ë³€í™˜ í›„ ê²€ìƒ‰í•˜ëŠ” ê¸°ë²•.

```
[ì¼ë°˜ RAG]
ì§ˆë¬¸("ì—°ì°¨ ëª‡ì¼?") â”€â”€â–º ì„ë² ë”© â”€â”€â–º ê²€ìƒ‰ â”€â”€â–º ë‹µë³€

[HyDE]
ì§ˆë¬¸ â”€â”€â–º LLM(ê°€ìƒ ë‹µë³€ ìƒì„±) â”€â”€â–º ê°€ìƒ ë‹µë³€ ì„ë² ë”© â”€â”€â–º ê²€ìƒ‰ â”€â”€â–º ë‹µë³€
```

### ì™œ íš¨ê³¼ì ì¸ê°€?
- ì§§ì€ ì§ˆë¬¸ â†” ê¸´ ë¬¸ì„œ ê°„ **semantic gap í•´ì†Œ**
- ì§ˆë¬¸ í˜•íƒœ vs ë‹µë³€ í˜•íƒœì˜ ì„ë² ë”© ë¶„í¬ê°€ ë‹¤ë¦„
- ê°€ìƒ ë‹µë³€ì€ ì‹¤ì œ ë¬¸ì„œì™€ ì„ë² ë”© ê³µê°„ì—ì„œ ë” ê°€ê¹Œì›€

### ì„±ëŠ¥
- Zero-shotìœ¼ë¡œ **10-12% ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**
- í•œêµ­ì–´/ì¼ë³¸ì–´ ë“± ë¹„ì˜ì–´ê¶Œì—ì„œë„ íš¨ê³¼ì 
- BM25, Contriever ëŒ€ë¹„ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒ

### êµ¬í˜„ ì˜ˆì‹œ
```python
# LlamaIndex
from llama_index.core.indices.query.query_transform.base import HyDEQueryTransform

hyde = HyDEQueryTransform(include_original=True)
query_engine = TransformQueryEngine(base_engine, query_transform=hyde)

# LangChain
from langchain.chains import HypotheticalDocumentEmbedder

hyde_embedder = HypotheticalDocumentEmbedder.from_llm(
    llm=llm,
    base_embeddings=embeddings,
    prompt_key="web_search"  # ë˜ëŠ” custom prompt
)
```

### ë‹¨ì 
- LLM 1íšŒ ì¶”ê°€ í˜¸ì¶œ â†’ ë ˆì´í„´ì‹œ ì¦ê°€
- ê°€ìƒ ë‹µë³€ì´ ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ìƒì„±ë  ìˆ˜ ìˆìŒ

### ë„ì… ì‹œì 
- ê²€ìƒ‰ í’ˆì§ˆì´ ê¸°ëŒ€ì— ë¯¸ì¹˜ì§€ ëª»í•  ë•Œ
- ì§ˆë¬¸ì´ ì¶”ìƒì ì´ê±°ë‚˜ ë³µì¡í•  ë•Œ

### ì°¸ê³  ìë£Œ
- [HyDE ì› ë…¼ë¬¸ (arXiv 2022)](https://arxiv.org/abs/2212.10496)
- [Zilliz - Improve RAG with HyDE](https://zilliz.com/learn/improve-rag-and-information-retrieval-with-hyde-hypothetical-document-embeddings)

---

## 2. Query Decomposition (ì§ˆë¬¸ ë¶„í•´) â­ ì‹ ê·œ

### ê°œìš”
ë³µì¡í•œ ì§ˆë¬¸ì„ ë‹¨ìˆœí•œ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´ í›„ ê°ê° ê²€ìƒ‰.

```
ì›ë³¸ ì§ˆë¬¸: "Aì‚¬ì™€ Bì‚¬ì˜ ì—°ì°¨ ì •ì±… ì°¨ì´ì ì€?"
      â†“ ë¶„í•´
["Aì‚¬ì˜ ì—°ì°¨ ì •ì±…ì€?", "Bì‚¬ì˜ ì—°ì°¨ ì •ì±…ì€?"]
      â†“ ê°ê° ê²€ìƒ‰
[Aì‚¬ ë¬¸ì„œë“¤, Bì‚¬ ë¬¸ì„œë“¤]
      â†“ í†µí•© + Rerank
ìµœì¢… ì»¨í…ìŠ¤íŠ¸
```

### 2025 ì—°êµ¬ ê²°ê³¼
| í”„ë ˆì„ì›Œí¬ | ì„±ëŠ¥ í–¥ìƒ | íŠ¹ì§• |
|-----------|----------|------|
| [Question Decomposition RAG](https://aclanthology.org/2025.acl-srw.32.pdf) | MRR@10 +36.7%, F1 +11.6% | ë¶„í•´ â†’ ê²€ìƒ‰ â†’ Rerank |
| [HopRAG](https://arxiv.org/html/2502.12442v1) | ë‹µë³€ ì •í™•ë„ +76.78% | ê·¸ë˜í”„ ê¸°ë°˜ ë‹¤ë‹¨ê³„ ì¶”ë¡  |
| [MQRF-RAG](https://dl.acm.org/doi/10.1145/3728199.3728221) | HotPotQA +7% | 4ê°€ì§€ ì¿¼ë¦¬ ìŠ¤íƒ€ì¼ ìƒì„± |

### êµ¬í˜„ ì˜ˆì‹œ
```python
# LlamaIndex Multi-Step Query
from llama_index.core.query_engine import MultiStepQueryEngine
from llama_index.core.indices.query.query_transform import StepDecomposeQueryTransform

step_decompose = StepDecomposeQueryTransform(llm=llm, verbose=True)
query_engine = MultiStepQueryEngine(
    query_engine=base_engine,
    query_transform=step_decompose,
    num_steps=3
)
```

### ë„ì… ì‹œì 
- ë¹„êµ ì§ˆë¬¸ì´ ë§ì„ ë•Œ ("Aì™€ Bì˜ ì°¨ì´", "X vs Y")
- ë‹¤ë‹¨ê³„ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸
- ë‹¨ì¼ ê²€ìƒ‰ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì´ ë‚®ì„ ë•Œ

### ì°¸ê³  ìë£Œ
- [Haystack - Query Decomposition Cookbook](https://haystack.deepset.ai/cookbook/query_decomposition)
- [MultiHop-RAG Benchmark](https://openreview.net/forum?id=t4eB3zYWBK)

---

## 3. Late Chunking (í›„ê¸° ì²­í‚¹) â­ ì‹ ê·œ

### ê°œìš”
ì²­í‚¹ í›„ ì„ë² ë”©ì´ ì•„ë‹Œ, ì„ë² ë”© í›„ ì²­í‚¹ìœ¼ë¡œ ë¬¸ë§¥ ë³´ì¡´.

```
[ê¸°ì¡´ ë°©ì‹]
ë¬¸ì„œ â”€â”€â–º ì²­í¬ ë¶„í•  â”€â”€â–º ê° ì²­í¬ ê°œë³„ ì„ë² ë”© (ë¬¸ë§¥ ì†ì‹¤!)

[Late Chunking]
ë¬¸ì„œ â”€â”€â–º ì „ì²´ í† í° ì„ë² ë”© â”€â”€â–º í† í° ì„ë² ë”©ì„ ì²­í¬ë¡œ ë¶„í•  â”€â”€â–º Mean Pooling
```

### ì™œ íš¨ê³¼ì ì¸ê°€?
- "ê·¸ëŠ”", "ì´ íšŒì‚¬" ê°™ì€ ëŒ€ëª…ì‚¬ ì°¸ì¡° ë¬¸ë§¥ ë³´ì¡´
- ì „ì²´ ë¬¸ì„œì˜ attention ì •ë³´ê°€ ê° ì²­í¬ì— ë°˜ì˜ë¨

### ì„±ëŠ¥
- ëŒ€ëª…ì‚¬ ì°¸ì¡° ë¬¸ì„œì—ì„œ **10-12% ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**
- ì¶”ê°€ í•™ìŠµ ì—†ì´ ì ìš© ê°€ëŠ¥
- Contextual Retrieval ëŒ€ë¹„ **ë¹„ìš© íš¨ìœ¨ì **

### vs Contextual Retrieval
| ë°©ì‹ | ë¹„ìš© | ì •í™•ë„ | êµ¬í˜„ ë³µì¡ë„ |
|------|------|--------|------------|
| Late Chunking | ë‚®ìŒ (ì„ë² ë”©ë§Œ) | ì¤‘-ìƒ | ì¤‘ê°„ |
| Contextual Retrieval | ë†’ìŒ (LLM í˜¸ì¶œ) | ìƒ | ë†’ìŒ |

### ì œì•½ ì‚¬í•­
- Long-context ì„ë² ë”© ëª¨ë¸ í•„ìš” (jina-embeddings-v2 ë“±)
- ì¸ë±ì‹± ì‹œì ì— ì ìš© (ì¿¼ë¦¬ ì‹œì  ì•„ë‹˜)

### ì°¸ê³  ìë£Œ
- [Jina AI - Late Chunking](https://jina.ai/news/late-chunking-in-long-context-embedding-models/)
- [Weaviate - Late Chunking](https://weaviate.io/blog/late-chunking)
- [Late Chunking Paper (arXiv)](https://arxiv.org/abs/2409.04701)
- [GitHub - jina-ai/late-chunking](https://github.com/jina-ai/late-chunking)

---

## 4. Anthropic Contextual Retrieval â­ ì‹ ê·œ

### ê°œìš”
ê° ì²­í¬ì— LLMìœ¼ë¡œ ë¬¸ë§¥ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” Anthropicì˜ ë°©ì‹.

```
ì›ë³¸ ì²­í¬: "ê·¸ëŠ” 2024ë…„ CEOê°€ ë˜ì—ˆë‹¤"
      â†“ LLM ë¬¸ë§¥ ì¶”ê°€
ë³´ê°•ëœ ì²­í¬: "[ì´ ë¬¸ì„œëŠ” ì‚¼ì„±ì „ì ì´ì¬ìš© íšŒì¥ì— ëŒ€í•œ ê²ƒì…ë‹ˆë‹¤] ê·¸ëŠ” 2024ë…„ CEOê°€ ë˜ì—ˆë‹¤"
```

### ì„±ëŠ¥ (Anthropic ê³µì‹)
- ê²€ìƒ‰ ì‹¤íŒ¨ìœ¨ **49% ê°ì†Œ**
- Reranking ê²°í•© ì‹œ **67% ê°ì†Œ**

### ë¹„ìš© ìµœì í™”: Prompt Caching
```
ì¼ë°˜ ë°©ì‹: ì²­í¬ë§ˆë‹¤ ì „ì²´ ë¬¸ì„œ ì „ë‹¬ â†’ ë¹„ìš© í­ë°œ

Prompt Caching í™œìš©:
1. ì „ì²´ ë¬¸ì„œë¥¼ ìºì‹œì— í•œ ë²ˆ ë¡œë“œ
2. ê° ì²­í¬ ì²˜ë¦¬ ì‹œ ìºì‹œëœ ë¬¸ì„œ ì°¸ì¡°
â†’ ë¹„ìš© 90% ì ˆê°, ë ˆì´í„´ì‹œ 85% ê°ì†Œ (11.5s â†’ 2.4s)
```

**ì˜ˆìƒ ë¹„ìš©**: ì²­í¬ë‹¹ ì•½ $1.02/M í† í° (800í† í° ì²­í¬, 8K ë¬¸ì„œ ê¸°ì¤€)

### ë„ì… ì‹œì 
- ê²€ìƒ‰ í’ˆì§ˆì´ ë§¤ìš° ì¤‘ìš”í•  ë•Œ
- í† í° ë¹„ìš©ì„ ê°ë‹¹í•  ìˆ˜ ìˆì„ ë•Œ
- ëŒ€ëª…ì‚¬/ì°¸ì¡°ê°€ ë§ì€ ë¬¸ì„œ

### ì°¸ê³  ìë£Œ
- [Anthropic - Contextual Retrieval ë°œí‘œ](https://www.anthropic.com/news/contextual-retrieval)
- [Anthropic Engineering - Contextual Retrieval](https://www.anthropic.com/engineering/contextual-retrieval)
- [Anthropic - Prompt Caching](https://www.anthropic.com/news/prompt-caching)

---

## 5. ê³ ê¸‰ Reranker ì˜µì…˜ â­ ì‹ ê·œ

### 2025 Reranker ë¹„êµ

| ëª¨ë¸ | ì •í™•ë„ | ì†ë„ | ë¹„ìš© | ë‹¤êµ­ì–´ | íŠ¹ì§• |
|------|--------|------|------|--------|------|
| **FlashRank** | Good | Very Fast | Free | ì œí•œì  | ONNX, CPU ìµœì í™” |
| **BGE-reranker-v2-m3** | High | Moderate | Free | âœ… | ì˜¤í”ˆì†ŒìŠ¤ SOTA |
| **Cohere Rerank 3.5** | High | Fast | API | âœ… 100+ | í”„ë¡œë•ì…˜ ì•ˆì •ì„± |
| **Cohere Rerank 3.5 Nimble** | High | Very Fast | API | âœ… | ì†ë„ ìµœì í™” ë²„ì „ |
| **Voyage Rerank 2.5** | Very High | Fast | API | âœ… | ìµœì‹  SOTA |

### rerankers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
```python
from rerankers import Reranker

# FlashRank (í˜„ì¬ ê³„íš)
ranker = Reranker("ms-marco-MiniLM-L-12-v2", model_type="flashrank")

# BGE (ë” ì •í™•, ë¬´ë£Œ) - ì¶”ì²œ
ranker = Reranker("BAAI/bge-reranker-v2-m3", model_type="cross-encoder")

# Cohere (API, í”„ë¡œë•ì…˜)
ranker = Reranker("rerank-english-v3.0", model_type="cohere")

# ì‚¬ìš©
results = ranker.rank(query="ì§ˆë¬¸", docs=["ë¬¸ì„œ1", "ë¬¸ì„œ2", ...])
```

### ê¶Œì¥ ì „ëµ
1. **ì‹œì‘**: FlashRank (ë¹ ë¥´ê³  ë¬´ë£Œ)
2. **í’ˆì§ˆ ê°œì„  í•„ìš”ì‹œ**: BGE-reranker-v2-m3
3. **í”„ë¡œë•ì…˜ + ë‹¤êµ­ì–´**: Cohere Rerank 3.5

### ì°¸ê³  ìë£Œ
- [ZeroEntropy - Best Reranking Model 2025](https://www.zeroentropy.dev/articles/ultimate-guide-to-choosing-the-best-reranking-model-in-2025)
- [Agentset Reranker Leaderboard](https://agentset.ai/rerankers)
- [AnswerDotAI/rerankers GitHub](https://github.com/AnswerDotAI/rerankers)

---

## 6. ColBERT v2 / Late Interaction Models â­ ì‹ ê·œ

### ê°œìš”
Cross-Encoder ìˆ˜ì¤€ ì •í™•ë„ + Bi-Encoder ìˆ˜ì¤€ ì†ë„ë¥¼ ì œê³µí•˜ëŠ” ëª¨ë¸.

```
[Bi-Encoder]
Query â”€â”€â–º ì„ë² ë”© â”€â”€â”
                  â”œâ”€â”€â–º ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë¹ ë¦„, ëœ ì •í™•)
Doc â”€â”€â–º ì„ë² ë”© â”€â”€â”€â”˜

[Cross-Encoder]
(Query, Doc) â”€â”€â–º í•¨ê»˜ ì¸ì½”ë”© â”€â”€â–º ì ìˆ˜ (ëŠë¦¼, ì •í™•)

[ColBERT - Late Interaction]
Query â”€â”€â–º í† í°ë³„ ì„ë² ë”© â”€â”€â”
                         â”œâ”€â”€â–º MaxSim (ë¹ ë¦„ + ì •í™•)
Doc â”€â”€â–º í† í°ë³„ ì„ë² ë”© â”€â”€â”€â”€â”˜
```

### ColBERTv2 íŠ¹ì§•
- ê³µê°„ íš¨ìœ¨: ê¸°ì¡´ ëŒ€ë¹„ **6-10ë°° ì ˆê°** (Residual Compression)
- [PLAID Engine](https://dl.acm.org/doi/10.1145/3511808.3557325): GPUì—ì„œ 7ë°°, CPUì—ì„œ 45ë°° ë¹ ë¦„
- 140M íŒ¨ì‹œì§€ì—ì„œë„ ìˆ˜ì‹­~ìˆ˜ë°± ms ë ˆì´í„´ì‹œ

### Jina-ColBERT-v2 (2024)
- **ë‹¤êµ­ì–´ ì§€ì›** í¬í•¨
- ColBERTv2 ëŒ€ë¹„ ê°œì„ ëœ í•™ìŠµ íŒŒì´í”„ë¼ì¸

### ë„ì… ì‹œì 
- ëŒ€ê·œëª¨ ê²€ìƒ‰ + ë†’ì€ ì •í™•ë„ê°€ ëª¨ë‘ í•„ìš”í•  ë•Œ
- Cross-Encoderê°€ ë„ˆë¬´ ëŠë¦´ ë•Œ

### ì°¸ê³  ìë£Œ
- [ColBERTv2 Paper](https://arxiv.org/abs/2112.01488)
- [Jina-ColBERT-v2 Paper](https://arxiv.org/abs/2408.16672)
- [Weaviate - Late Interaction Overview](https://weaviate.io/blog/late-interaction-overview)
- [Stanford ColBERT GitHub](https://github.com/stanford-futuredata/ColBERT)

---

## 7. Voyage AI Embeddings â­ ì‹ ê·œ

### 2025 ì„ë² ë”© ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | vs OpenAI text-embedding-3-large | ì°¨ì› | ì»¨í…ìŠ¤íŠ¸ | ë¹„ìš© |
|------|----------------------------------|------|----------|------|
| **voyage-3-large** | **+9.74%** | 1024-2048 | 32K | ë¹„ìŠ· |
| **voyage-3.5** | **+8.26%** | 2048 | 32K | 2.2ë°° ì €ë ´ |
| **voyage-3.5-lite** | **+6.34%** | 2048 | 32K | 6.5ë°° ì €ë ´ |
| OpenAI text-embedding-3-large | ê¸°ì¤€ | 3072 | 8K | ê¸°ì¤€ |
| Amazon Titan | - | 1024 | 8K | ì €ë ´ |

### Voyage AI ì¥ì 
- **32K í† í° ì»¨í…ìŠ¤íŠ¸** (OpenAI 8Kì˜ 4ë°°)
- **Matryoshka ì„ë² ë”©**: ì°¨ì› ì¡°ì ˆ ê°€ëŠ¥ (2048 â†’ 256)
- **ë‹¤êµ­ì–´ ì„±ëŠ¥ ìš°ìˆ˜** (í•œêµ­ì–´ í¬í•¨)
- int8/binary ì–‘ìí™”ë¡œ **ë²¡í„°DB ë¹„ìš© 83% ì ˆê°**

### ë„ì… ì‹œì 
- Amazon Titanë³´ë‹¤ ë†’ì€ ì •í™•ë„ í•„ìš” ì‹œ
- ê¸´ ë¬¸ì„œ ì„ë² ë”©ì´ í•„ìš”í•  ë•Œ

### ì°¸ê³  ìë£Œ
- [Voyage AI - voyage-3-large ë°œí‘œ](https://blog.voyageai.com/2025/01/07/voyage-3-large/)
- [Voyage AI - voyage-3.5 ë°œí‘œ](https://blog.voyageai.com/2025/05/20/voyage-3-5/)
- [Best Embedding Models 2025](https://elephas.app/blog/best-embedding-models)

---

## 8. Semantic Chunking (ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹) â­ ì‹ ê·œ

### ê°œìš”
ê³ ì • í¬ê¸°ê°€ ì•„ë‹Œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¬¸ì„œ ë¶„í• .

```
[Fixed-size Chunking]
ë¬¸ì„œ â”€â”€â–º 500í† í°ì”© ìë¥´ê¸° (ë¬¸ì¥ ì¤‘ê°„ì— ëŠê¸¸ ìˆ˜ ìˆìŒ)

[Semantic Chunking]
ë¬¸ì„œ â”€â”€â–º ë¬¸ì¥ ì„ë² ë”© â”€â”€â–º ìœ ì‚¬ë„ ê¸‰ë³€ ì§€ì ì—ì„œ ë¶„í• 
```

### ì„±ëŠ¥ (2025 ì—°êµ¬)
- ê³ ì • í¬ê¸° ëŒ€ë¹„ **15-30% ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**
- [Max-Min Semantic Chunking](https://link.springer.com/article/10.1007/s10791-025-09638-7): ì˜ë¯¸ì  ì¼ê´€ì„± ë³´ì¡´

### ë‹¨ì 
- ì²­í‚¹ ì‹œ ì„ë² ë”© ë¹„ìš© ë°œìƒ
- êµ¬í˜„ ë³µì¡ë„ ì¦ê°€

### í˜„ì‹¤ì  ëŒ€ì•ˆ
```python
# RecursiveCharacterTextSplitterê°€ ì¢‹ì€ ê¸°ë³¸ê°’
# 400-512 í† í°, 10-20% ì˜¤ë²„ë© â†’ 85-90% recall
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", " "]
)
```

### ì°¸ê³  ìë£Œ
- [Firecrawl - Best Chunking Strategies 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)
- [Weaviate - Chunking Strategies](https://weaviate.io/blog/chunking-strategies-for-rag)

---

## 9. Context Compression (ì»¨í…ìŠ¤íŠ¸ ì••ì¶•)

### ê°œìš”
ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ë°”ë¡œ ì „ë‹¬í•˜ì§€ ì•Šê³ , ë¨¼ì € ì••ì¶•/ìš”ì•½ í›„ ì „ë‹¬.

```
[ì¼ë°˜ RAG]
ê²€ìƒ‰ê²°ê³¼(10K í† í°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º LLM â”€â”€â–º ë‹µë³€

[Context Compression]
ê²€ìƒ‰ê²°ê³¼(10K í† í°) â”€â”€â–º LLM(ì••ì¶•) â”€â”€â–º ì••ì¶•ë³¸(2K) â”€â”€â–º LLM â”€â”€â–º ë‹µë³€
```

### ì¥ì 
- í† í° ë¹„ìš© ì ˆê° (íŠ¹íˆ GPT-4 ê°™ì€ ê³ ê°€ ëª¨ë¸)
- ê¸´ ì»¨í…ìŠ¤íŠ¸ì˜ ë…¸ì´ì¦ˆ ì œê±°
- "Lost in the Middle" ë¬¸ì œ ì™„í™”

### ë‹¨ì 
- LLM 2ë²ˆ í˜¸ì¶œ (ë ˆì´í„´ì‹œ ì¦ê°€)
- ì••ì¶• ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ ê°€ëŠ¥
- êµ¬í˜„ ë³µì¡ë„ ì¦ê°€

### ë„ì… ì‹œì 
- ì»¨í…ìŠ¤íŠ¸ê°€ consistently 10K+ í† í°ì¼ ë•Œ
- í† í° ë¹„ìš©ì´ ë³‘ëª©ì¼ ë•Œ
- ë‹µë³€ í’ˆì§ˆì´ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¸í•´ ì €í•˜ë  ë•Œ

### ì°¸ê³  ìë£Œ
- [Contextual Compression in RAG Survey (arXiv)](https://arxiv.org/html/2409.13385v1)
- LangChain `ContextualCompressionRetriever`

---

## 10. Dynamic Context Selection (ë™ì  ì»¨í…ìŠ¤íŠ¸ ì„ íƒ)

### ê°œìš”
ì¿¼ë¦¬ íŠ¹ì„±ì— ë”°ë¼ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜(k)ë‚˜ í¬ë§·ì„ ë™ì ìœ¼ë¡œ ê²°ì •.

```python
# ì˜ˆì‹œ: ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ kê°’ ì¡°ì ˆ
def select_k(query: str) -> int:
    complexity = classify_query(query)  # LLM ë˜ëŠ” classifier
    if complexity == "simple":
        return 3
    elif complexity == "complex":
        return 10
    return 5
```

### 2025 ì—°êµ¬: DynamicRAG
[DynamicRAG Paper](https://medium.com/@sindhuja.codes/when-to-rerank-and-when-to-let-semantic-search-do-its-job-af3adddd602b)
- ê³ ì • k ëŒ€ì‹  **ë™ì ìœ¼ë¡œ ë¬¸ì„œ ìˆ˜ ê²°ì •**
- Reranking í•„ìš” ì—¬ë¶€ë„ ë™ì  íŒë‹¨

### í˜„ì‹¤ì  ëŒ€ì•ˆ (ì§€ê¸ˆ ì“¸ ìˆ˜ ìˆìŒ)
```python
def select_k_simple(query: str) -> int:
    # Rule-based: LLM í˜¸ì¶œ ì—†ì´
    if "ë¹„êµ" in query or "ì°¨ì´" in query:
        return 7  # ë¹„êµ ì§ˆë¬¸ì€ ë” ë§ì´
    if len(query) < 20:
        return 3  # ì§§ì€ ì§ˆë¬¸ì€ ì ê²Œ
    return 5
```

### ì°¸ê³  ìë£Œ
- [Dynamic Context Selection for RAG (arXiv)](https://arxiv.org/html/2512.14313)
- [Adaptive-RAG Framework](https://arxiv.org/html/2506.00054v1)

---

## 11. Context Awareness Gate (CAG)

### ê°œìš”
"ì´ ì§ˆë¬¸ì— ì™¸ë¶€ ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œê°€?"ë¥¼ ë¨¼ì € íŒë‹¨.

```
ì§ˆë¬¸ â”€â”€â–º CAG íŒë‹¨ â”€â”€â”¬â”€â”€ í•„ìš”í•¨ â”€â”€â–º RAG íŒŒì´í”„ë¼ì¸ â”€â”€â–º ë‹µë³€
                   â”‚
                   â””â”€â”€ ë¶ˆí•„ìš” â”€â”€â–º LLM ì§ì ‘ ë‹µë³€
```

### ì¥ì 
- LLM ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œ ì¶©ë¶„í•œ ì§ˆë¬¸ì€ ê²€ìƒ‰ ìƒëµ
- ë ˆì´í„´ì‹œ ë° ë¹„ìš© ì ˆê°

### ë‹¨ì 
- íŒë‹¨ ì˜¤ë¥˜ ì‹œ hallucination ìœ„í—˜
- ê¸°ì—… ë‚´ë¶€ ë¬¸ì„œ RAGì—ì„œëŠ” ëŒ€ë¶€ë¶„ ê²€ìƒ‰ í•„ìš”

### ë„ì… ì‹œì 
- ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ê³¼ ë„ë©”ì¸ ì§ˆë¬¸ì´ í˜¼ì¬í•  ë•Œ
- ê²€ìƒ‰ì´ ë¶ˆí•„ìš”í•œ ì§ˆë¬¸ì´ ìƒë‹¹ìˆ˜ì¼ ë•Œ

### ì°¸ê³  ìë£Œ
- [Context Awareness Gate for RAG (arXiv)](https://arxiv.org/html/2411.16133)

---

## 12. Hierarchical RAG (ê³„ì¸µì  ê²€ìƒ‰)

### ê°œìš”
ë¬¸ì„œ â†’ ì„¹ì…˜ â†’ ë‹¨ë½ ìˆœìœ¼ë¡œ ê³„ì¸µì  ê²€ìƒ‰.

```
1. í›„ë³´ ë¬¸ì„œ ê²€ìƒ‰ (top 20)
      â†“
2. ë¬¸ì„œ ë‚´ ê´€ë ¨ ì„¹ì…˜ ê²€ìƒ‰ (top 10)
      â†“
3. ì„¹ì…˜ ë‚´ ê´€ë ¨ ë‹¨ë½ ê²€ìƒ‰ (top 5)
      â†“
4. ìµœì¢… ë‹¨ë½ë§Œ LLMì— ì „ë‹¬
```

### ì¥ì 
- ëŒ€ê·œëª¨ ë¬¸ì„œì—ì„œ ì •ë°€í•œ ê²€ìƒ‰
- "Lost in the Middle" ì™„í™”
- ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í–¥ìƒ

### ë‹¨ì 
- ì¸ë±ì‹± ë³µì¡ë„ ì¦ê°€
- ê²€ìƒ‰ ë‹¨ê³„ ì¦ê°€ë¡œ ë ˆì´í„´ì‹œ ì¦ê°€

### ë„ì… ì‹œì 
- ë¬¸ì„œê°€ ë§¤ìš° ê¸¸ê³  êµ¬ì¡°í™”ë˜ì–´ ìˆì„ ë•Œ
- ë‹¨ì¼ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ê°€ ë¶€ì¡±í•  ë•Œ

---

## 13. Parent-Child Retrieval (Sentence Window)

### ê°œìš”
ì‘ì€ ì²­í¬ë¡œ ê²€ìƒ‰í•˜ê³ , í° ì²­í¬ë¡œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ.

```
ì¸ë±ì‹±:
- Parent ì²­í¬: 2000 í† í° (LLM ì»¨í…ìŠ¤íŠ¸ìš©)
- Child ì²­í¬: 200 í† í° (ê²€ìƒ‰ìš©)

ê²€ìƒ‰:
Childë¡œ ê²€ìƒ‰ â”€â”€â–º Parent ì²­í¬ ë°˜í™˜ â”€â”€â–º LLM
(ì •ë°€ ê²€ìƒ‰)      (ì¶©ë¶„í•œ ë¬¸ë§¥)
```

### ì¥ì 
- ê²€ìƒ‰ ì •ë°€ë„ + ì»¨í…ìŠ¤íŠ¸ ì™„ì „ì„± ëª¨ë‘ í™•ë³´
- êµ¬í˜„ ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨

### ì°¸ê³  ìë£Œ
- [LlamaIndex - Sentence Window Retrieval](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo/)

---

## 14. Query-Aware Context Formatting (ì¿¼ë¦¬ ì¸ì‹ í¬ë§·íŒ…)

### ê°œìš”
ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì»¨í…ìŠ¤íŠ¸ í¬ë§·ì„ ë‹¤ë¥´ê²Œ êµ¬ì„±.

| ì§ˆë¬¸ ìœ í˜• | ì¶”ì²œ í¬ë§· |
|----------|----------|
| ì‚¬ì‹¤ í™•ì¸ | ê°„ë‹¨í•œ ë²ˆí˜¸ ëª©ë¡ |
| ë¹„êµ ì§ˆë¬¸ | í…Œì´ë¸” í˜•íƒœ |
| ë¶„ì„ ì§ˆë¬¸ | ìƒì„¸ ë©”íƒ€ë°ì´í„° í¬í•¨ |

### ì—°êµ¬ ê²°ê³¼
[arXiv 2411.10541](https://arxiv.org/html/2411.10541v1)ì— ë”°ë¥´ë©´:
- GPT-3.5: í¬ë§·ì— ë”°ë¼ **ìµœëŒ€ 40% ì„±ëŠ¥ ì°¨ì´**
- GPT-4: ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì 
- **ìµœì  í¬ë§·ì´ ëª¨ë¸/íƒœìŠ¤í¬ë§ˆë‹¤ ë‹¤ë¦„**

### í˜„ì‹¤ì  ì ‘ê·¼
LLMì—ê²Œ í¬ë§· ê²°ì •ì„ ë§¡ê¸°ëŠ” ê²ƒë³´ë‹¤, A/B í…ŒìŠ¤íŠ¸ë¡œ ìµœì  í¬ë§·ì„ ì°¾ì•„ ê³ ì •í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì .

---

## í˜„ì¬ ì ìš© ê¸°ìˆ 

### LongContextReorder (Lost in the Middle ëŒ€ì‘)

```python
def reorder_for_attention(results: list[dict]) -> list[dict]:
    """
    U-shaped attention íŒ¨í„´ í™œìš©
    - ê°€ì¥ ê´€ë ¨ë„ ë†’ì€ ë¬¸ì„œ: ì²˜ìŒê³¼ ëì— ë°°ì¹˜
    - ê´€ë ¨ë„ ë‚®ì€ ë¬¸ì„œ: ì¤‘ê°„ì— ë°°ì¹˜
    """
    reordered = []
    for i, doc in enumerate(results):
        if i % 2 == 0:
            reordered.insert(len(reordered) // 2, doc)
        else:
            reordered.append(doc)
    return reordered
```

**ê·¼ê±°**: [Lost in the Middle (Stanford, 2024)](https://arxiv.org/abs/2307.03172)
- ì¤‘ê°„ ìœ„ì¹˜ ì •ë³´ ë¬´ì‹œ â†’ ìµœëŒ€ 30% ì„±ëŠ¥ ì €í•˜
- Reorderë¡œ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ íšŒë³µ

---

## ì°¸ê³  ë¬¸í—Œ

### RAG ì¼ë°˜
1. [A Survey of Context Engineering for LLMs (2025)](https://arxiv.org/abs/2507.13334)
2. [Lost in the Middle: How Language Models Use Long Contexts (2024)](https://arxiv.org/abs/2307.03172)
3. [VectorHub - Optimizing RAG with Hybrid Search & Reranking](https://superlinked.com/vectorhub/articles/optimizing-rag-with-hybrid-search-reranking)
4. [Advanced RAG Techniques - Neo4j](https://neo4j.com/blog/genai/advanced-rag-techniques/)

### Reranking
5. [Pinecone - Rerankers](https://www.pinecone.io/learn/series/rag/rerankers/)
6. [ZeroEntropy - Best Reranking Model 2025](https://www.zeroentropy.dev/articles/ultimate-guide-to-choosing-the-best-reranking-model-in-2025)
7. [Agentset Reranker Leaderboard](https://agentset.ai/rerankers)

### Chunking
8. [Best Chunking Strategies for RAG 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)
9. [Weaviate - Chunking Strategies](https://weaviate.io/blog/chunking-strategies-for-rag)
10. [Jina AI - Late Chunking](https://jina.ai/news/late-chunking-in-long-context-embedding-models/)

### Query Transformation
11. [HyDE Paper (arXiv 2022)](https://arxiv.org/abs/2212.10496)
12. [Haystack - Query Decomposition](https://haystack.deepset.ai/cookbook/query_decomposition)
13. [HopRAG Paper (2025)](https://arxiv.org/html/2502.12442v1)

### Embeddings
14. [Voyage AI - voyage-3-large](https://blog.voyageai.com/2025/01/07/voyage-3-large/)
15. [Voyage AI - voyage-3.5](https://blog.voyageai.com/2025/05/20/voyage-3-5/)
16. [Best Embedding Models 2025](https://elephas.app/blog/best-embedding-models)

### Anthropic
17. [Anthropic - Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)
18. [Anthropic - Prompt Caching](https://www.anthropic.com/news/prompt-caching)

### Late Interaction
19. [ColBERTv2 Paper](https://arxiv.org/abs/2112.01488)
20. [Jina-ColBERT-v2 Paper](https://arxiv.org/abs/2408.16672)
21. [Weaviate - Late Interaction Overview](https://weaviate.io/blog/late-interaction-overview)

### ê¸°íƒ€
22. [Does Prompt Formatting Have Any Impact on LLM Performance? (2024)](https://arxiv.org/abs/2411.10541)
23. [Contextual Compression in RAG Survey (2024)](https://arxiv.org/html/2409.13385v1)
24. [Context Awareness Gate for RAG (2024)](https://arxiv.org/html/2411.16133)
25. [Dynamic Context Selection for RAG (2024)](https://arxiv.org/html/2512.14313)
