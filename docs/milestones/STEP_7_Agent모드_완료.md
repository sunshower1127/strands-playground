# STEP 7: Strands Agent ëª¨ë“œ ì¶”ê°€

## ìƒíƒœ: ì™„ë£Œ âœ…

## ëª©í‘œ
Strands Agentë¥¼ ì‚¬ìš©í•œ ììœ¨ì  RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„

---

## êµ¬í˜„

### í•  ì¼

- [x] Strands SDK ì„¤ì¹˜ ë° ì„¤ì •
- [x] LiteLLM ëª¨ë¸ í”„ë¡œë°”ì´ë” ì„¤ì • (Vertex AI Claude)
- [x] OpenSearch ê²€ìƒ‰ ë„êµ¬ (@tool) êµ¬í˜„
- [x] Agent RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- [x] ëª¨ë“œ ì „í™˜ êµ¬ì¡° (basic â†” agent)
- [x] Agent ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [x] ì½”ë“œ êµ¬ì¡° ë¦¬íŒ©í† ë§

---

## 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
uv add "strands-agents[litellm]" strands-agents-tools
```

---

## 2. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
src/
â”œâ”€â”€ __init__.py           # create_service() í—¬í¼
â”œâ”€â”€ service.py            # íŒ©í† ë¦¬ í•¨ìˆ˜
â”œâ”€â”€ types.py              # RAGServiceBase, ServiceResult
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_agent.py      # AgentRAG í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ service.py        # AgentRAGService
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ search.py     # search_documents ë„êµ¬
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py       # RAGPipeline
â”‚   â”œâ”€â”€ service.py        # RAGService
â”‚   â”œâ”€â”€ types.py          # RAGResult
â”‚   â””â”€â”€ modules/          # íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸
â””â”€â”€ (ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ë“¤)
```

---

## 3. ì‚¬ìš©ë²•

### í—¬í¼ í•¨ìˆ˜ (ê¶Œì¥)

```python
from src import create_service

# Basic RAG
service = create_service(mode="basic")
result = service.query("ì—°ì°¨ íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?")

# Agent RAG
service = create_service(mode="agent")
result = service.query("ì—°ì°¨ íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?")
```

### ì§ì ‘ ì‚¬ìš©

```python
# Basic RAG
from src.rag import RAGService
service = RAGService(project_id=334, pipeline="minimal")

# Agent RAG
from src.agent import AgentRAGService
service = AgentRAGService(project_id=334)
```

---

## 4. ê³µí†µ ì¸í„°í˜ì´ìŠ¤

```python
# src/types.py
class RAGServiceBase(ABC):
    @abstractmethod
    def query(self, question: str) -> ServiceResult:
        pass

@dataclass
class ServiceResult:
    mode: str           # "basic" | "agent"
    question: str
    answer: str
    input_tokens: int
    output_tokens: int
    latency_ms: float
    model: str
    sources: list[dict]      # Basic ëª¨ë“œ
    tool_calls: list[dict]   # Agent ëª¨ë“œ
    timings: dict[str, float] # Basic ëª¨ë“œ
```

---

## 5. ê²€ìƒ‰ ë„êµ¬ (`src/agent/tools/search.py`)

```python
from strands import tool

@tool
def search_documents(query: str, k: int = 5, project_id: int = 334) -> str:
    """OpenSearchì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # ì„ë² ë”© ìƒì„± â†’ KNN ê²€ìƒ‰ â†’ ê²°ê³¼ í¬ë§·íŒ…
    ...
```

---

## 6. Agent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸

```python
AGENT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆë¬¸ ë‹µë³€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ë‹¤ìŒ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- search_documents: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ë¨¼ì € ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ íŒŒì•…í•˜ì„¸ìš”
2. search_documents ë„êµ¬ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
3. ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰í•˜ì„¸ìš”
4. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
5. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
6. ë‹µë³€í•  ë•Œ ê·¼ê±°ê°€ ëœ ë¬¸ì„œë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”
"""
```

---

## 7. LiteLLM ì„¤ì • (Vertex AI)

```python
from strands.models.litellm import LiteLLMModel

model = LiteLLMModel(
    model_id="vertex_ai/claude-sonnet-4-5@20250929",
    params={
        "vertex_project": os.getenv("GCP_PROJECT_ID"),
        "vertex_location": os.getenv("GCP_REGION", "us-east5"),
        "max_tokens": 1024,
    },
)
```

---

## 8. í…ŒìŠ¤íŠ¸ ê²°ê³¼

### Basic vs Agent ë¹„êµ

| í•­ëª© | Basic | Agent |
|------|-------|-------|
| ë ˆì´í„´ì‹œ | ~8,600ms | ~15,000ms |
| ê²€ìƒ‰ ë°©ì‹ | ê³ ì • 1íšŒ | ììœ¨ì  (1~4íšŒ) |
| ì†ŒìŠ¤ | 5ê°œ ë°˜í™˜ | ë„êµ¬ í˜¸ì¶œ ì •ë³´ |
| íŠ¹ì§• | ì˜ˆì¸¡ ê°€ëŠ¥ | ìœ ì—°í•œ íƒìƒ‰ |

### í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´

```bash
# Agent ë‹¨ë… í…ŒìŠ¤íŠ¸
uv run python scripts/test_agent.py
uv run python scripts/test_agent.py "ì¶œì¥ë¹„ ì •ì‚°ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"

# í†µí•© í…ŒìŠ¤íŠ¸
uv run python -c "
from src import create_service
service = create_service(mode='agent')
result = service.query('ì—°ì°¨ íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?')
print(result.answer)
"
```

---

## 9. íŒŒì¼ ëª©ë¡

| íŒŒì¼ | ì„¤ëª… |
|------|------|
| `src/types.py` | ê³µí†µ ì¸í„°í˜ì´ìŠ¤ (RAGServiceBase, ServiceResult) |
| `src/service.py` | create_service() íŒ©í† ë¦¬ í•¨ìˆ˜ |
| `src/agent/rag_agent.py` | AgentRAG í´ë˜ìŠ¤ |
| `src/agent/service.py` | AgentRAGService (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„) |
| `src/agent/tools/search.py` | search_documents ë„êµ¬ |
| `src/rag/service.py` | RAGService (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„) |
| `scripts/test_agent.py` | Agent í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ |

---

## 10. ë¬¸ì œ í•´ê²°

### í† í° ëˆ„ì  ë²„ê·¸

**ë¬¸ì œ**: ì§ˆë¬¸ë§ˆë‹¤ í† í°ì´ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€ (Q1: 8K â†’ Q13: 1.3M í† í°)

**ì›ì¸**: `AgentRAGService`ì—ì„œ Agent ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ëˆ„ì ë¨. Strands AgentëŠ” ê¸°ë³¸ì ìœ¼ë¡œ `SlidingWindowConversationManager`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ìœ ì§€.

**í•´ê²°**: ë§¤ ì¿¼ë¦¬ë§ˆë‹¤ ìƒˆ Agent ìƒì„± (stateless)

```python
# src/agent/service.py
def query(self, question: str) -> ServiceResult:
    # ë§¤ë²ˆ ìƒˆ Agent ìƒì„± (stateless)
    agent = AgentRAG(project_id=self.project_id)
    result = agent.query(question)
    return ServiceResult(...)
```

**ëŒ€ì•ˆ**:
- `agent.agent.messages = []`ë¡œ ìˆ˜ë™ ì´ˆê¸°í™”
- `NullConversationManager` ì‚¬ìš©

**ì°¸ê³ **: [Issue #329: reset() method ìš”ì²­](https://github.com/strands-agents/sdk-python/issues/329)

---

## í–¥í›„ ê°œì„ 

### Context Awareness Gate (CAG)

"ì´ ì§ˆë¬¸ì— ì™¸ë¶€ ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œê°€?"ë¥¼ ë¨¼ì € íŒë‹¨.

```
ì§ˆë¬¸ â”€â”€â–º CAG íŒë‹¨ â”€â”€â”¬â”€â”€ í•„ìš”í•¨ â”€â”€â–º RAG íŒŒì´í”„ë¼ì¸ â”€â”€â–º ë‹µë³€
                   â”‚
                   â””â”€â”€ ë¶ˆí•„ìš” â”€â”€â–º LLM ì§ì ‘ ë‹µë³€
```

Agent ëª¨ë“œì—ì„œëŠ” ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ë¯€ë¡œ CAGê°€ ì•”ë¬µì ìœ¼ë¡œ ì ìš©ë¨.

### Dynamic Context Selection

ì¿¼ë¦¬ íŠ¹ì„±ì— ë”°ë¼ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜(k)ë‚˜ í¬ë§·ì„ ë™ì ìœ¼ë¡œ ê²°ì •.

### Gemini ëª¨ë¸ ë„ì… ê²€í† 

í˜„ì¬ Claudeë¥¼ ì‚¬ìš© ì¤‘ì´ë‚˜, í–¥í›„ Gemini ë„ì… ì‹œ ì°¸ê³ í•  ë‚´ìš©.

#### LiteLLM vs Native Provider

| ë°©ì‹ | ì¥ì  | ë‹¨ì  |
|------|------|------|
| **LiteLLM ê²½ìœ ** (í˜„ì¬) | íŒ¨ì¹˜ ë¶ˆí•„ìš”, ë²”ìš©ì , Fallback ì§€ì› | ~50ms ì˜¤ë²„í—¤ë“œ |
| **Strands Native** | ì§ì ‘ ì—°ê²°, Provider íŠ¹í™” ê¸°ëŠ¥ | ì‹ ê·œ ëª¨ë¸ì€ PR ëŒ€ê¸° í•„ìš” |

LiteLLM ì˜¤ë²„í—¤ë“œ:
- ê³µì‹ ë²¤ì¹˜ë§ˆí¬: ~3.25ms ~ 50ms
- ëª¨ë“  ì‘ë‹µì— `x-litellm-overhead-duration-ms` í—¤ë”ë¡œ ì¸¡ì • ê°€ëŠ¥

#### Gemini ì‚¬ìš© ì‹œ ëª¨ë¸ ì„¤ì •

```python
# LiteLLMìœ¼ë¡œ Gemini ì‚¬ìš© (íŒ¨ì¹˜ ë¶ˆí•„ìš”)
model = LiteLLMModel(
    model_id="vertex_ai/gemini-2.5-flash",  # ë˜ëŠ” gemini-2.5-pro
    params={
        "vertex_project": os.getenv("GCP_PROJECT_ID"),
        "vertex_location": "us-central1",
        "max_tokens": 2048,
    },
)
```

#### Gemini 3.0 Thought Signature

Gemini 3.0ì—ì„œ ë„ì…ëœ **ë©€í‹°í„´ ì¶”ë¡  ìƒíƒœ ìœ ì§€ ë©”ì»¤ë‹ˆì¦˜**.

**ê°œë…:**
```
[Turn 1] User â†’ Gemini â†’ Tool Call + thought_signature ë°˜í™˜
                              â†“
[Turn 2] Tool ê²°ê³¼ + thought_signature ì „ë‹¬ â†’ Gemini â†’ ì¶”ë¡  ì´ì–´ì„œ â†’ ì‘ë‹µ
```

- ì•”í˜¸í™”ëœ í† í°ìœ¼ë¡œ "ì™œ ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí–ˆëŠ”ì§€" ì¶”ë¡  ë§¥ë½ ë³´ì¡´
- **í•„ìˆ˜ ìš”ê±´**: Gemini 3.0ì—ì„œ Tool Call ì‹œ signature ë¯¸ì „ë‹¬í•˜ë©´ 4xx ì—ëŸ¬

**Gemini 2.5 vs 3.0:**

| êµ¬ë¶„ | Gemini 2.5 | Gemini 3.0 |
|------|------------|------------|
| ìƒíƒœ | Stateless | Stateful (Thought Signature) |
| Tool Call ì‹œ | ê·¸ëƒ¥ í˜¸ì¶œ | `thought_signature` í•„ìˆ˜ ë°˜í™˜ |
| ë‹¤ìŒ í„´ | ì»¨í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬ | signatureë„ í•¨ê»˜ ì „ë‹¬ í•„ìˆ˜ |

**ë„ì… í•„ìš”ì„±:**

| ìƒí™© | í•„ìš” ì—¬ë¶€ |
|------|----------|
| ë‹¨ìˆœ Q&A | âŒ |
| 1-2ë²ˆ Tool Call | âŒ |
| ë³µì¡í•œ Multi-step ì¶”ë¡  (5+ Tool Calls) | ğŸ”¶ ë„ì›€ë¨ |
| ì¥ê¸° ì‹¤í–‰ Agent (ìˆ˜ì‹­ ë²ˆ Tool Call) | âœ… ìœ ì˜ë¯¸ |

**í˜„ì¬ ê²°ë¡ **: ìš°ë¦¬ ì›Œí¬í”Œë¡œìš°(1-2íšŒ Tool Call)ì—ì„œëŠ” ì˜¤ë²„ìŠ¤í™. Claude + LiteLLMìœ¼ë¡œ ì¶©ë¶„.

**Strandsì—ì„œ Gemini 3.0 ì‚¬ìš© ì‹œ í•„ìš”í•œ íŒ¨ì¹˜:**
- [PR #1040](https://github.com/strands-agents/sdk-python/pull/1040): Vertex AI ì§ì ‘ ì§€ì›
- [PR #1382](https://github.com/strands-agents/sdk-python/pull/1382): Gemini 3.0 thought_signature ì§€ì›

**ì°¸ê³  ë¬¸ì„œ:**
- [Google AI - Thought Signatures](https://ai.google.dev/gemini-api/docs/thought-signatures)
- [Vertex AI - Thought Signatures](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/thought-signatures)
- [LiteLLM Gemini 3 ì§€ì›](https://docs.litellm.ai/blog/gemini_3)

### ì°¸ê³  ìë£Œ

- [Strands Agents ë¬¸ì„œ](https://strandsagents.com/latest/)
- [LiteLLM Vertex AI](https://docs.litellm.ai/docs/providers/vertex_partner)
- [LiteLLM Benchmarks](https://docs.litellm.ai/docs/benchmarks)
- [Context Awareness Gate (arXiv)](https://arxiv.org/html/2411.16133)
- [Dynamic Context Selection (arXiv)](https://arxiv.org/html/2512.14313)
